{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5sHdwKk0TCm",
        "outputId": "2f2c92f6-63db-4876-f5ab-8ab9d1581829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAq_Ko7tgTK4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from transformers import BertTokenizer, AdamW, get_linear_schedule_with_warmup, BertModel\n",
        "import torch\n",
        "import copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "import time, sys\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive',)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "959w-nbR6iN7",
        "outputId": "4279bd19-b6be-4509-e47c-0a7bad2f4971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataPrep(Dataset):\n",
        "    def __init__(self, filedata,tokenizer,label_to_id = None, category_to_id=None):\n",
        "        super(DataPrep, self).__init__()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.filedata = filedata\n",
        "        columns = ['opinion', 'categories', 'word', 'position', 'sentence']\n",
        "        self.data = pd.read_csv(filedata, sep = '\\t', names=columns)\n",
        "        \n",
        "        if label_to_id is not None :\n",
        "            self.label_to_id = label_to_id\n",
        "        else :\n",
        "            possible_labels = self.data.opinion.unique().tolist()\n",
        "            self.label_to_id = {label:k for k, label in enumerate(possible_labels)}\n",
        "\n",
        "        if category_to_id is not None :\n",
        "            self.category_to_id = category_to_id \n",
        "        else :\n",
        "            possible_categories = self.data.categories.unique().tolist()\n",
        "            self.category_to_id = {label:k for k, label in enumerate(possible_categories)}\n",
        "        \n",
        "        self.id_to_label = {id:label for label, id in self.label_to_id.items()}\n",
        "        self.id_to_category = {id:category for category, id in self.category_to_id.items()}\n",
        "        \n",
        "        #self.data = self.dftoid(self.data)\n",
        "\n",
        "        opinion = self.data.opinion.tolist()\n",
        "        sentences = self.data.sentence.tolist()\n",
        "        position = self.data.position.tolist()\n",
        "        categories = self.data.categories.tolist()\n",
        "\n",
        "        sentences_tokenized = []\n",
        "        ind_words_to_guess = []\n",
        "        labels = []\n",
        "        category_list = []\n",
        "        self.token_id_begin, self.token_id_end, self.token_id_pad = self.tokenizer(\"\", return_token_type_ids=False, return_attention_mask=False, padding=\"max_length\", max_length=3)['input_ids']\n",
        "\n",
        "\n",
        "        for i, s in enumerate(sentences):\n",
        "            interval = position[i].split(\":\")\n",
        "            ind0, ind1 = int(interval[0]), int(interval[1])\n",
        "            tokens, ind_start, ind_end = self.convert_sentence_to_tokens(s, ind0, ind1)\n",
        "            sentences_tokenized.append(tokens)\n",
        "            ind_words_to_guess.append([ind_start, ind_end])\n",
        "            labels.append(self.label_to_id[opinion[i]])\n",
        "            category_list.append(self.category_to_id[categories[i]])\n",
        "\n",
        "        self.sentences_tokenized = sentences_tokenized\n",
        "        self.ind_words_to_guess = ind_words_to_guess\n",
        "        self.labels = labels\n",
        "        self.category_list = category_list\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, index) :\n",
        "        return self.sentences_tokenized[index], self.ind_words_to_guess[index], self.labels[index], self.category_list[index]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "    # def dftoid(self, df):\n",
        "        \n",
        "    #     df['opinion'] = [self.label_to_id[label] for label in df.opinion]\n",
        "    #     df['categories'] = [self.category_to_id[cat] for cat in df.categories]\n",
        "    #     return df\n",
        "\n",
        "    def convert_sentence_to_tokens(self, sentence, ind0, ind1):\n",
        "        tokens_list = [self.token_id_begin]\n",
        "        if ind0 > 0 : \n",
        "            tokens_list += self.tokenizer.encode_plus(sentence[:ind0],add_special_tokens=True, return_token_type_ids =False, return_attention_mask =False)['input_ids'][1:-1]\n",
        "            \n",
        "        ind_start = len(tokens_list)\n",
        "        tokens_list += self.tokenizer.encode_plus(sentence[ind0:ind1],add_special_tokens=True, return_token_type_ids =False, return_attention_mask =False)['input_ids'][1:-1]\n",
        "        ind_end = len(tokens_list)\n",
        "\n",
        "        if ind1 < len(sentence) :\n",
        "            tokens_list += self.tokenizer.encode_plus(sentence[ind1:], add_special_tokens=True,return_token_type_ids =False, return_attention_mask =False)['input_ids'][1:-1]\n",
        "\n",
        "        tokens_list += [self.token_id_end]\n",
        "\n",
        "        return tokens_list, ind_start, ind_end"
      ],
      "metadata": {
        "id": "kceuwiWbgnDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BertClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BertClassifier, self).__init__()\n",
        "        \n",
        "      \n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        self.common_linear = nn.Linear(2*768,768)\n",
        "\n",
        "        for i in range(12):\n",
        "          setattr(self, 'linear_%i' % i, nn.Linear(768, 3))\n",
        "\n",
        "    def forward(self, data):\n",
        "        features = self.bert(data[\"data\"])[0]\n",
        "        last_hidden_state_cls = features[:, 0, :]\n",
        "        output = []\n",
        "        for k, feat in enumerate(features) :\n",
        "            mean_feat = torch.mean(feat[data[\"words_id\"][k][0]:data[\"words_id\"][k][1],:], dim=0)\n",
        "            mean_feat = torch.cat((mean_feat, last_hidden_state_cls[k,:]),0)\n",
        "            mean_feat = torch.relu(self.common_linear(mean_feat))\n",
        "            out = getattr(self, 'linear_' + str(int(data[\"categories\"][k])))(mean_feat)\n",
        "            output.append(out)\n",
        "\n",
        "        return torch.stack(output)"
      ],
      "metadata": {
        "id": "dB9rxCS_3z05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(batch, pad_id):\n",
        "    length_to_pad = max([len(item[0]) for item in batch])\n",
        "    sentences = []\n",
        "    ind_words_to_guess = []\n",
        "    labels = []\n",
        "    category_list = []\n",
        "    for item in batch :\n",
        "      sentences.append(item[0] + (length_to_pad-len(item[0])) * [pad_id])\n",
        "      ind_words_to_guess.append(item[1])\n",
        "      labels.append(item[2])\n",
        "      category_list.append(item[3])\n",
        "    return torch.tensor(sentences), torch.tensor(ind_words_to_guess), torch.tensor(labels), torch.tensor(category_list)\n",
        "\n",
        "def train_epch(dataloader, criterion, optimizer, model, device,scheduler, epch):\n",
        "    model.train()\n",
        "    train_loss = 0.\n",
        "    for _, (data, words_id, labels, categories) in enumerate(dataloader):\n",
        "        data = data.to(device)\n",
        "        words_id = words_id.to(device)      \n",
        "        labels = labels.to(device)\n",
        "        categories = categories.to(device)\n",
        "\n",
        "        outputs = model({\"data\":data, \"words_id\":words_id, \"categories\":categories})\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        train_loss += loss.item()\n",
        "    print(\"Training done epoch {}!     Loss : {}\".format(epch, round(train_loss,3)))\n",
        "\n",
        "def eval_epch(dataloader,criterion, model, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    predicted_list = []\n",
        "    with torch.no_grad():\n",
        "        for _, (data, words_id, labels, categories) in enumerate(dataloader):\n",
        "            data = data.to(device)\n",
        "            words_id = words_id.to(device)      \n",
        "            categories = categories.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model({\"data\":data, \"words_id\":words_id, \"categories\":categories})\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            predicted_list.append(int(predicted))\n",
        "\n",
        "            total += labels.size(0) \n",
        "            correct += (predicted == labels).sum().item()\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "    print(\"Evaluation done! Accuracy : {}%\".format(round(correct/total*100,1)))\n",
        "    return  loss, predicted_list\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f65KP0xC31eD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier:\n",
        "    def __init__(self):\n",
        "        #self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.tokenizer = self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        self.model = None\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "        #attribute that will be filled during training\n",
        "        self.label_to_id = None\n",
        "        self.category_to_id = None\n",
        "\n",
        "\n",
        "    def initialize_model(self,train_dataloader, epochs, device, catego = True, freeze_bert=False):\n",
        "        \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
        "        \"\"\"\n",
        "        # Instantiate Bert Classifier\n",
        "        self.model = BertClassifier().to(device)\n",
        "\n",
        "        # Tell PyTorch to run the model on GPU\n",
        "        self.model.to(device)\n",
        "\n",
        "        # Create the optimizer\n",
        "        self.optimizer = AdamW(self.model.parameters(),\n",
        "                        lr=8e-5,    # Default learning rate\n",
        "                        eps=1e-8    # Default epsilon value\n",
        "                        )\n",
        "\n",
        "        # Total number of training steps\n",
        "        total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "        # Set up the learning rate scheduler\n",
        "        self.scheduler = get_linear_schedule_with_warmup(self.optimizer,\n",
        "                                                    num_warmup_steps=4, # Default value\n",
        "                                                    num_training_steps=total_steps)\n",
        "        # exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "        #return bert_classifier, optimizer, scheduler\n",
        "\n",
        "\n",
        "\n",
        "    #############################################\n",
        "    def train(self, train_filename, dev_filename, device):\n",
        "        \"\"\"Trains the classifier model on the training set stored in file trainfile\"\"\"\n",
        "        batch_size = 32\n",
        "        epochs = 3\n",
        "        train_dataset = DataPrep(train_filename, self.tokenizer)\n",
        "        train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn= lambda b: custom_collate_fn(b, train_dataset.token_id_pad))\n",
        "        #val_dataset = DataPrep(\"../data/devdata.csv\", self.tokenizer, self.label_to_id, self.category_to_id)\n",
        "        #val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn= lambda b: custom_collate_fn(b, val_dataset.token_id_pad))\n",
        "\n",
        "        self.label_to_id = train_dataset.label_to_id\n",
        "        self.category_to_id = train_dataset.category_to_id\n",
        "        self.initialize_model(train_dataloader,epochs, device)\n",
        "        #optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
        "        #criterion = nn.CrossEntropyLoss()\n",
        "        best_loss = np.inf\n",
        "\n",
        "        for epch in range(epochs):\n",
        "            train_epch(train_dataloader, self.loss_fn, self.optimizer, self.model, device,self.scheduler, epch)\n",
        "        #     loss_eval,_ = eval_epch(val_dataloader,self.loss_fn, self.model, self.device) \n",
        "        #     print('Evaluation done: loss: '+str(loss_eval.item()))\n",
        "        #     if loss_eval<best_loss:\n",
        "        #       best_loss = loss_eval\n",
        "        #       best_model = copy.deepcopy(self.model.state_dict())\n",
        "        \n",
        "        # self.model.load_state_dict(best_model)\n",
        "\n",
        "            \n",
        "    \n",
        "    def predict(self, data_filename, device):\n",
        "        \"\"\"Predicts class labels for the input instances in file 'datafile'\n",
        "        Returns the list of predicted labels\n",
        "        \"\"\"\n",
        "        val_dataset = DataPrep(data_filename, self.tokenizer, self.label_to_id, self.category_to_id)\n",
        "        val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False, collate_fn= lambda b: custom_collate_fn(b, val_dataset.token_id_pad))\n",
        "        _, predicted_list = eval_epch(val_dataloader,self.loss_fn, self.model, device)\n",
        "        print(predicted_list)\n",
        "        return [val_dataset.id_to_label[pred] for pred in predicted_list]"
      ],
      "metadata": {
        "id": "e_0WNlVTSCwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_reproducible():\n",
        "    # The below is necessary to have reproducible behavior.\n",
        "    import random as rn\n",
        "    import os\n",
        "    os.environ['PYTHONHASHSEED'] = '0'\n",
        "    # The below is necessary for starting Numpy generated random numbers\n",
        "    # in a well-defined initial state.\n",
        "    np.random.seed(17)\n",
        "    # The below is necessary for starting core Python generated random numbers\n",
        "    # in a well-defined state.\n",
        "    rn.seed(12345)\n",
        "\n",
        "\n",
        "\n",
        "def load_label_output(filename):\n",
        "    with open(filename, 'r', encoding='UTF-8') as f:\n",
        "        return [line.strip().split(\"\\t\")[0] for line in f if line.strip()]\n",
        "\n",
        "\n",
        "\n",
        "def eval_list(glabels, slabels):\n",
        "    if (len(glabels) != len(slabels)):\n",
        "        print(\"\\nWARNING: label count in system output (%d) is different from gold label count (%d)\\n\" % (\n",
        "        len(slabels), len(glabels)))\n",
        "    n = min(len(slabels), len(glabels))\n",
        "    incorrect_count = 0\n",
        "    for i in range(n):\n",
        "        if slabels[i] != glabels[i]: incorrect_count += 1\n",
        "    acc = (n - incorrect_count) / n\n",
        "    return acc*100\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pJeBDgJF4E5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_eval(classifier, trainfile, devfile, testfile, run_id, device):\n",
        "    print(f\"\\nRUN: {run_id}\")\n",
        "    print(\"  %s.1. Training the classifier...\" % str(run_id))\n",
        "    classifier.train(trainfile, devfile, device)\n",
        "    print()\n",
        "    print(\"  %s.2. Eval on the dev set...\" % str(run_id), end=\"\")\n",
        "    slabels = classifier.predict(devfile, device)\n",
        "    glabels = load_label_output(devfile)\n",
        "    devacc = eval_list(glabels, slabels)\n",
        "    print(\" Acc.: %.2f\" % devacc)\n",
        "    testacc = -1\n",
        "    if testfile is not None:\n",
        "        # Evaluation on the test data\n",
        "        print(\"  %s.3. Eval on the test set...\" % str(run_id), end=\"\")\n",
        "        slabels = classifier.predict(testfile)\n",
        "        glabels = load_label_output(testfile)\n",
        "        testacc = eval_list(glabels, slabels)\n",
        "        print(\" Acc.: %.2f\" % testacc)\n",
        "    print()\n",
        "    return (devacc, testacc)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AiBTF82t7g2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#argparser = argparse.ArgumentParser()\n",
        "#argparser.add_argument('-n', '--n_runs', help='Number of runs.', type=int, default=5)\n",
        "#argparser.add_argument('-g', '--gpu', help='GPU device id on which to run the model', type=int)\n",
        "#args = argparser.parse_args()\n",
        "#device_name = \"cpu\" if args.gpu is None else f\"cuda:{args.gpu}\"\n",
        "#device = torch.device(device_name)\n",
        "device = \"cuda\"\n",
        "#n_runs = args.n_runs\n",
        "n_runs = 1\n",
        "set_reproducible()\n",
        "datadir = \"/content/\"\n",
        "trainfile =  datadir + \"traindata.csv\"\n",
        "devfile =  datadir + \"devdata.csv\"\n",
        "testfile = None\n",
        "# testfile = datadir + \"testdata.csv\""
      ],
      "metadata": {
        "id": "Z9m433-FGxDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Runs\n",
        "start_time = time.perf_counter()\n",
        "devaccs = []\n",
        "testaccs = []\n",
        "for i in range(1, n_runs+1):\n",
        "    classifier =  Classifier()\n",
        "    devacc, testacc = train_and_eval(classifier, trainfile, devfile, testfile, i, device)\n",
        "    devaccs.append(np.round(devacc,2))\n",
        "    testaccs.append(np.round(testacc,2))\n",
        "print('\\nCompleted %d runs.' % n_runs)\n",
        "total_exec_time = (time.perf_counter() - start_time)\n",
        "print(\"Dev accs:\", devaccs)\n",
        "print(\"Test accs:\", testaccs)\n",
        "print()\n",
        "print(\"Mean Dev Acc.: %.2f (%.2f)\" % (np.mean(devaccs), np.std(devaccs)))\n",
        "print(\"Mean Test Acc.: %.2f (%.2f)\" % (np.mean(testaccs), np.std(testaccs)))\n",
        "print(\"\\nExec time: %.2f s. ( %d per run )\" % (total_exec_time, total_exec_time / n_runs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "punq1AnDMzIb",
        "outputId": "41c63bbc-b968-4835-dcd9-63fb628a8355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "RUN: 1\n",
            "  1.1. Training the classifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training done epoch 0!     Loss : 35.774\n",
            "Training done epoch 1!     Loss : 21.922\n",
            "Training done epoch 2!     Loss : 12.851\n",
            "\n",
            "  1.2. Eval on the dev set...Evaluation done! Accuracy : 85.4%\n",
            "[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0]\n",
            " Acc.: 85.37\n",
            "\n",
            "\n",
            "Completed 1 runs.\n",
            "Dev accs: [85.37]\n",
            "Test accs: [-1]\n",
            "\n",
            "Mean Dev Acc.: 85.37 (0.00)\n",
            "Mean Test Acc.: -1.00 (0.00)\n",
            "\n",
            "Exec time: 55.45 s. ( 55 per run )\n"
          ]
        }
      ]
    }
  ]
}
